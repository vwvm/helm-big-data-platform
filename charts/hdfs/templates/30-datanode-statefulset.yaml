apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: hadoop-datanode
  labels:
    app: hadoop
    component: datanode
spec:
  serviceName: "hadoop-datanode"
  replicas: {{ .Values.datanode.replicas }}
  selector:
    matchLabels:
      app: hadoop
      component: datanode
  template:
    metadata:
      labels:
        app: hadoop
        component: datanode
    spec:
      securityContext:
        runAsUser: 0
        runAsGroup: 0
        fsGroup: 0
      initContainers:
        - name: init-datanode-dir
          image: docker.1ms.run/apache/hadoop:3.4.1
          command:
            - "sh"
            - "-c"
            - |
              mkdir -p /hadoop/data/dfs/data /hadoop/logs
              chmod -R 777 /hadoop/data /hadoop/logs
              # 初始化时清理数据，确保每次启动都是干净的
              rm -rf /hadoop/data/dfs/data/*
          volumeMounts:
            - name: hadoop-data-dir
              mountPath: /hadoop/data
            - name: hadoop-logs-dir
              mountPath: /hadoop/logs
      containers:
        - name: datanode
          image: docker.1ms.run/apache/hadoop:3.4.1
          command: [ "hdfs", "datanode" ]
          ports:
            - containerPort: 9864
              name: data
          env:
            - name: HADOOP_USER_NAME
              value: "root"
          resources:
            requests:
              memory: "512Mi"
              cpu: "250m"
            limits:
              memory: "1Gi"
              cpu: "500m"
          volumeMounts:
            - name: hadoop-config-volume
              mountPath: /opt/hadoop/etc/hadoop/core-site.xml
              subPath: core-site.xml
            - name: hadoop-config-volume
              mountPath: /opt/hadoop/etc/hadoop/hdfs-site.xml
              subPath: hdfs-site.xml
            # 使用临时存储（Pod删除时数据丢失）
            - name: hadoop-data-dir
              mountPath: /hadoop/data
            - name: hadoop-logs-dir
              mountPath: /hadoop/logs
            - name: nfs-pvc
              mountPath: /opt/hadoop/share/hadoop/common/lib/hadoop-lzo-0.4.20.jar
              subPath: lib/hadoop-lzo-0.4.20.jar
      volumes:
        - name: hadoop-config-volume
          configMap:
            name: hadoop-config
        - name: hadoop-data-dir
          emptyDir: {}
        - name: hadoop-logs-dir
          emptyDir: {}
        - name: nfs-pvc
          persistentVolumeClaim:
            claimName: nfs-pvc

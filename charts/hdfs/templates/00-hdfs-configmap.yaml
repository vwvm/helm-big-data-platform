# hadoop-config.yml：Hadoop核心配置（ConfigMap形式）
apiVersion: v1
kind: ConfigMap
metadata:
  name: hadoop-config
  labels:
    app: hadoop
    component: config
data:
  # 核心配置：指定HDFS地址和通信方式
  core-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://hadoop-namenode:8020</value>
        </property>
        <property>
            <name>hadoop.tmp.dir</name>
            <value>/tmp/hadoop-root</value>
        </property>
        <property>
            <name>hadoop.http.staticuser.user</name>
            <value>root</value>
        </property>
    </configuration>

  # HDFS配置：副本数和数据存储目录
  hdfs-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
        <property>
            <name>dfs.replication</name>
            <value>2</value>
        </property>
        <property>
            <name>dfs.namenode.rpc-address</name>
            <value>hadoop-namenode:8020</value>
        </property>
        <property>
            <name>dfs.namenode.name.dir</name>
            <value>/tmp/hadoop-root/dfs/name</value>
        </property>
        <property>
            <name>dfs.datanode.data.dir</name>
            <value>/tmp/hadoop-root/dfs/data</value>
        </property>
        
        <property>
            <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
            <value>false</value>
        </property>
        <property>
            <name>dfs.client.use.datanode.hostname</name>
            <value>false</value>
        </property>
        <property>
            <name>dfs.datanode.use.datanode.hostname</name>
            <value>false</value>
        </property>
        
        <property>
            <name>dfs.namenode.rpc-bind-host</name>
            <value>0.0.0.0</value>
        </property>
        <property>
            <name>dfs.namenode.http-bind-host</name>
            <value>0.0.0.0</value>
        </property>
    </configuration>

  # YARN 资源配置
  yarn-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
        <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>hadoop-resourcemanager</value>
        </property>
        <property>
            <name>yarn.resourcemanager.address</name>
            <value>hadoop-resourcemanager:8032</value>  <!-- 主机名:端口（8032 是 RM 客户端 RPC 端口） -->
        </property>
        <property>
            <name>yarn.nodemanager.pmem-check-enabled</name>
            <value>false</value>
        </property>
        <property>
            <name>yarn.nodemanager.delete.debug-delay-sec</name>
            <value>600</value>
        </property>
        <property>
            <name>yarn.nodemanager.vmem-check-enabled</name>
            <value>false</value>
        </property>
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
        <property>
            <name>yarn.nodemanager.resource.memory-mb</name>
            <value>{{ .Values.yarn.nodemanager.resource.memoryMb }}</value>
        </property>
        <property>
            <name>yarn.nodemanager.resource.cpu-vcores</name>
            <value>{{ .Values.yarn.nodemanager.resource.cpuVcores }}</value>
        </property>
        <!-- 关键：设置调度器最大分配 -->
        <property>
            <name>yarn.scheduler.maximum-allocation-mb</name>
            <value>{{ .Values.yarn.scheduler.maximumAllocationMb }}</value>
        </property>
        <property>
            <name>yarn.scheduler.maximum-allocation-vcores</name>
            <value>{{ .Values.yarn.scheduler.maximumAllocationVcores }}</value>
        </property>
        <!-- 最小分配 -->
        <property>
            <name>yarn.scheduler.minimum-allocation-mb</name>
            <value>{{ .Values.yarn.scheduler.minimumAllocationMb }}</value>
        </property>
        <property>
            <name>yarn.scheduler.minimum-allocation-vcores</name>
            <value>{{ .Values.yarn.scheduler.minimumAllocationVcores }}</value>
        </property>
    </configuration>

  # MapReduce 配置
  mapred-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
        <property>
            <name>yarn.app.mapreduce.am.env</name>
            <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
        </property>
        <property>
            <name>mapreduce.map.env</name>
            <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
        </property>
        <property>
            <name>mapreduce.reduce.env</name>
            <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
        </property>
        <property>
            <name>mapreduce.map.memory.mb</name>
            <value>{{ .Values.yarn.mapreduce.map.memory.mb }}</value>
        </property>
        <property>
            <name>mapreduce.reduce.memory.mb</name>
            <value>{{ .Values.yarn.mapreduce.reduce.memory.mb }}</value>
        </property>
        <property>
            <name>yarn.app.mapreduce.am.resource.mb</name>
            <value>{{ .Values.yarn.mapreduce.am.resource.mb }}</value>
        </property>
        
        <!-- 覆盖AM的JVM参数 -->
        <property>
            <name>yarn.app.mapreduce.am.command-opts</name>
            <value>-Xmx630m</value>
        </property>
        
        <!-- 覆盖Map任务的JVM参数 -->
        <property>
            <name>mapreduce.map.java.opts</name>
            <value>-Xmx630m</value>
        </property>
        
        <!-- 覆盖Reduce任务的JVM参数 -->
        <property>
            <name>mapreduce.reduce.java.opts</name>
            <value>-Xmx630m</value>
        </property>
    </configuration>
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-config
  namespace: default
data:
  spark-defaults.conf: |
    spark.master                     spark://spark-master:7077
    spark.eventLog.enabled           true
    spark.eventLog.dir               /opt/spark/spark-events
    spark.history.fs.logDirectory    /opt/spark/spark-events
    spark.serializer                 org.apache.spark.serializer.KryoSerializer
    spark.sql.catalogImplementation  hive

  spark-env.sh: |
    #!/bin/bash
    # This file is sourced when running various Spark programs
    export SPARK_MASTER_HOST=${SPARK_MASTER_HOST:-$(hostname -f)}
    export SPARK_MASTER_PORT=${SPARK_MASTER_PORT:-7077}
    export SPARK_MASTER_WEBUI_PORT=${SPARK_MASTER_WEBUI_PORT:-8080}
    export SPARK_LOG_DIR=${SPARK_LOG_DIR:-/opt/spark/logs}
    export SPARK_PID_DIR=${SPARK_PID_DIR:-/opt/spark/pids}
    export SPARK_LOCAL_IP=${SPARK_LOCAL_IP:-$(hostname -i)}

  log4j2.properties: |
    # 基本的日志配置
    status = error
    name = SparkConfig
    
    appender.console.type = Console
    appender.console.name = console
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
    
    rootLogger.level = info
    rootLogger.appenderRef.console.ref = console
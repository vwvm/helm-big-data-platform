apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-thrift-config
  labels:
    app: spark
    component: thrift-server-config
data:
  # ============ 1. Spark 环境配置文件 (spark-env.sh) ============
  spark-defaults.conf: |
    spark.master                   spark://spark-master:7077
    
    spark.sql.catalogImplementation hive
    spark.hadoop.hive.metastore.uris thrift://hive-metastore-service:9083
    spark.hadoop.fs.defaultFS      hdfs://hadoop-namenode:8020

  spark-env.sh: |
    export SPARK_DRIVER_MEMORY="512m"
    export SPARK_DRIVER_CORES="1"
    export SPARK_DRIVER_PORT="30000"
    export SPARK_DRIVER_BIND_ADDRESS="0.0.0.0"
    
    # 3. Executor 配置
    export SPARK_EXECUTOR_MEMORY="1000m"
    export SPARK_TOTAL_EXECUTOR_CORES="2"
    
    # 4. 网络和安全配置
    export SPARK_BLOCKMANAGER_PORT="30001"
    export SPARK_AUTHENTICATE="false"
    export SPARK_AUTHENTICATE_ENABLESASLENCRYPTION="false"
    export SPARK_NETWORK_CRYPTO_ENABLED="false"
    export SPARK_SSL_ENABLED="false"
    
    # 5. UI 配置
    export SPARK_UI_ENABLED="false"

  # ============ 2. 启动脚本 (无sleep，直接前台运行) ============
  start-thrift-server.sh: |
    #!/bin/bash
    set -e
    
    echo "Starting Spark Thrift Server..."
    
    # 加载配置
    if [ -f "/opt/spark/conf/spark-env.sh" ]; then
      source /opt/spark/conf/spark-env.sh
    fi
    
    # 构建Hadoop配置参数
    HADOOP_CONF_ARGS=""
    if [ -n "${SPARK_HADOOP_FS_DEFAULTFS}" ]; then
      HADOOP_CONF_ARGS="--conf spark.hadoop.fs.defaultFS=${SPARK_HADOOP_FS_DEFAULTFS}"
      HADOOP_CONF_ARGS="${HADOOP_CONF_ARGS} --conf spark.sql.warehouse.dir=${SPARK_HADOOP_FS_DEFAULTFS}/user/hive/warehouse"
    fi
    
    if [ -n "${SPARK_HIVE_METASTORE_URIS}" ]; then
      HADOOP_CONF_ARGS="${HADOOP_CONF_ARGS} --conf spark.hadoop.hive.metastore.uris=${SPARK_HIVE_METASTORE_URIS}"
    fi
    
    # 直接运行thriftserver（前台进程）
    exec /opt/spark/sbin/start-thriftserver.sh \
      --master spark://spark-master:7077 \
      --conf spark.driver.memory=${SPARK_DRIVER_MEMORY:-512m} \
      --conf spark.driver.cores=1 \
      --conf spark.executor.memory=${SPARK_EXECUTOR_MEMORY:-1000m} \
      --conf spark.cores.max=${SPARK_WORKER_CORES:-2} \
      --conf spark.driver.port=30000 \
      --conf spark.blockManager.port=30001 \
      --conf spark.driver.bindAddress=0.0.0.0 \
      --conf spark.driver.host=$(hostname -i) \
      --conf spark.sql.catalogImplementation=hive \
      ${HADOOP_CONF_ARGS} \
      --name "Spark-Thrift-Server" \
      --hiveconf hive.server2.thrift.port=10000 \
      --hiveconf hive.server2.thrift.bind.host=0.0.0.0
    # exec确保thriftserver成为容器主进程，容器生命周期与thriftserver一致
  
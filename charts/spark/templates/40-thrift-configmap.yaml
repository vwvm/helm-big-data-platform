# spark-thrift-final.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-thrift-config
  labels:
    app: spark
    component: thrift-server
data:
  # Hive 配置文件（给 Spark 用）
  hive-site.xml: |
    <?xml version="1.0"?>
    <configuration>
        <!-- Hive Metastore 连接 -->
        <property>
            <name>hive.metastore.uris</name>
            <value>thrift://hive-metastore-service:9083</value>
            <description>Hive Metastore URI</description>
        </property>
        
        <property>
            <name>hive.metastore.warehouse.dir</name>
            <value>/user/hive/warehouse</value>
            <description>Hive 数据仓库目录</description>
        </property>
        
        <!-- Hive 版本兼容性 -->
        <property>
            <name>hive.metastore.client.capability.check</name>
            <value>false</value>
        </property>
        
        <!-- 启用向量化 -->
        <property>
            <name>hive.vectorized.execution.enabled</name>
            <value>true</value>
        </property>
    </configuration>

  # Spark 配置文件
  spark-defaults.conf: |
    # ========== 基础配置 ==========
    spark.master                     spark://spark-master:7077
    spark.sql.catalogImplementation  hive
    spark.sql.warehouse.dir          /user/hive/warehouse
    
    # ========== Hive Metastore 连接 ==========
    spark.hadoop.hive.metastore.uris              thrift://hive-metastore-service:9083
    spark.sql.hive.metastore.version              3.1.3
    spark.sql.hive.metastore.jars                 builtin
    spark.sql.hive.metastore.sharedPrefixes       "com.mysql.jdbc,org.postgresql,com.microsoft.sqlserver,oracle.jdbc"
    
    # ========== 资源分配 ==========
    spark.executor.memory                         2g
    spark.executor.cores                          2
    spark.driver.memory                           1g
    spark.executor.instances                      2
    
    # ========== 性能优化 ==========
    spark.sql.adaptive.enabled                    true
    spark.sql.adaptive.coalescePartitions.enabled true
    spark.sql.adaptive.skewJoin.enabled           true
    spark.sql.autoBroadcastJoinThreshold          10485760
    
    # ========== 序列化 ==========
    spark.serializer                              org.apache.spark.serializer.KryoSerializer
    spark.kryoserializer.buffer.max               256m
    
    # ========== 动态分配 ==========
    spark.dynamicAllocation.enabled               true
    spark.dynamicAllocation.minExecutors          1
    spark.dynamicAllocation.maxExecutors          10
    spark.dynamicAllocation.initialExecutors      2
    
    # ========== Shuffle ==========
    spark.sql.shuffle.partitions                  200
    spark.sql.adaptive.shuffle.targetPostShuffleInputSize 67108864
---